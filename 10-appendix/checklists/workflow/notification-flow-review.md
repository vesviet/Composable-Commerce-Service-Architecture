# Notification Flows ‚Äî Business Logic Review Checklist

**Date**: 2026-02-21 | **Reviewer**: AI Review (Shopify/Shopee/Lazada patterns + codebase analysis)
**Scope**: `notification/` ‚Äî channels, event consumers, worker, preference/opt-out, outbox, GitOps
**Reference**: `docs/10-appendix/ecommerce-platform-flows.md` ¬ß11 (Notification Flows)

---

## üìä Summary

| Category | Status |
|----------|--------|
| üî¥ P0 ‚Äî Critical (missing critical notifications / data loss) | **‚úÖ 2/2 fixed** |
| üü° P1 ‚Äî High (reliability / compliance) | **‚úÖ 5/5 fixed** |
| üîµ P2 ‚Äî Medium (edge case / observability) | **4 open** |
| ‚úÖ Verified Working | 16+ areas |

---

## ‚úÖ Verified Fixed & Working Correctly

| Area | Verified? | Notes |
|------|-----------|-------|
| Atomic notification + outbox creation | ‚úÖ | `uc.transaction` wraps `repo.Create` + `outboxRepo.Save` in same TX (lines 161-188) |
| Idempotency via `correlationID` | ‚úÖ | `FindByCorrelationID` check before creating duplicate notification (lines 99-111) |
| User opt-out check at send time | ‚úÖ | `GlobalUnsubscribe` and per-channel `isChannelEnabled` checked at `SendNotification` (lines 83-94) |
| Permanent failure detection | ‚úÖ | `isPermanentFailure` correctly identifies: no-retry for expired, opted-out, bad recipient, unsupported channel |
| Quiet hours enforcement | ‚úÖ | `isInQuietHours` handles overnight (e.g. 22:00‚Äì07:00) correctly; reschedules to quiet-hours end |
| Daily rate limit enforcement | ‚úÖ | `CountDailyNotifications` compared to `MaxNotificationsPerDay` in worker before send |
| Retry with exponential backoff + jitter | ‚úÖ | `nextRetryDelay`: base 5min, max 1h, 20% jitter (lines 301-324) |
| Email SMTP fallback | ‚úÖ | Falls back to `smtpProvider` when `emailProvider` is disabled/nil |
| DLQ persistence for exhausted events | ‚úÖ | Both consumers persist failed events to `dead_letter_events` table via `dlqRepo.Save` |
| Idempotency via `processedEventRepo` | ‚úÖ | Both order + system_error consumers check `IsEventProcessed` before processing |
| 1-minute time-bucket dedup for system errors | ‚úÖ | Prevents duplicate Telegram alerts for identical errors within 60s |
| In-consumer 3-retry + exponential backoff | ‚úÖ | `HandleOrderStatusChanged` + `HandleSystemError` both retry with 100ms base backoff |
| Permanent error early-exit (decode/invalid) | ‚úÖ | `isPermanentError` breaks retry loop for JSON decode / invalid errors |
| Delivery log creation per send attempt | ‚úÖ | `deliveryUC.CreateDeliveryLog` called on each attempt with full response details |
| Lifecycle events published after send | ‚úÖ | `PublishNotificationDelivered` / `PublishNotificationFailed` on outcome |
| ProcessPendingNotifications every 30 seconds | ‚úÖ | Cron `"*/30 * * * * *"` (line 62) |
| Retry failed notifications every 5 minutes | ‚úÖ | Cron `"0 */5 * * * *"` (line 70) |
| Expired notification detection in worker | ‚úÖ | Lines 131-138: marks expired as `failed` before processing |
| Default preferences: all channels on | ‚úÖ | `getDefaultPreference` defaults ALL boolean fields to `true` |
| Unsubscribe token generation | ‚úÖ | `generateUnsubscribeToken` uses UUID-prefixed ID |

---

## üî¥ Open P0 Issues (Critical ‚Äî Essential Notifications Missing)

### NOTIF-P0-001: Order Status Consumer Only Notifies for NEW Orders ‚Äî All Other Status Changes Silently Dropped

**File**: `notification/internal/data/eventbus/order_status_consumer.go:178-218`

**Problem**: The `processOrderStatusChanged` function only triggers notifications for:
1. `OldStatus == ""` (new order)
2. `OldStatus == "pending" && NewStatus == "confirmed"` (COD auto-confirm)

**All other transitions are silently consumed and marked "processed":**
- `order.confirmed ‚Üí processing` (operator started pick)
- `processing ‚Üí shipped` ‚Üí No "Your order has been shipped" notification
- `shipped ‚Üí delivered` ‚Üí No "Your order was delivered" notification
- Any status ‚Üí `cancelled` ‚Üí No "Your order was cancelled" notification
- `confirmed ‚Üí payment_failed` ‚Üí No "Payment failed" alert to customer

The `formatOrderStatusChangedMessage` function (line 333) exists to format non-create status changes but is **dead code** (`//nolint: unused`).

Per ¬ß11.2: Shopee/Lazada send SMS + Push for `shipped`, Push + Email for `delivered`, Push + Email for `return approved`, and Email for `refund processed`.

**Resolution** ‚úÖ **FIXED 2026-02-22**:
- [x] Expanded `processOrderStatusChanged` using `resolveNotificationSpec()` dispatch table
- [x] Handles `‚Üí shipped`, `‚Üí delivered`, `‚Üí cancelled`, `‚Üí failed/payment_failed`, `‚Üí refunded`
- [x] Telegram channel with per-transition subject+emoji+priority
- [x] Dead `formatOrderStatusChangedMessage` reactivated as status-change formatter

---

### NOTIF-P0-002: No Consumer for Payment, Return, or Alert Events

**Problem**: The notification worker only subscribes to 2 event topics:
1. `orders.order.status_changed` ‚Üí `OrderStatusConsumer`
2. `system.errors` ‚Üí `SystemErrorConsumer`

Missing consumers for all high-priority notification triggers per ¬ß11.2:

| Expected Event | Channel(s) | Missing? |
|---------------|-----------|---------|
| `payment.confirmed` | Email + Push (payment receipt) | ‚ùå No consumer |
| `payment.failed` | Email + Push | ‚ùå No consumer |
| `return.approved` | Email + Push | ‚ùå No consumer |
| `refund.completed` | Email + Push | ‚ùå No consumer |
| `warehouse.inventory.low_stock_alert` | Push to seller | ‚ùå No consumer |
| Flash sale started | Push | ‚ùå No consumer |
| Price drop (wishlisted) | Push + Email | ‚ùå No consumer |

**Resolution** ‚úÖ **FIXED 2026-02-22**:
- [x] Added `PaymentEventConsumer` ‚Üí `payment.confirmed` + `payment.failed`
  - File: `notification/internal/data/eventbus/payment_event_consumer.go`
- [x] Added `ReturnEventConsumer` ‚Üí `return.approved` + `refund.completed`
  - File: `notification/internal/data/eventbus/return_event_consumer.go`
- [x] Both consumers: idempotency via `processedEventRepo`, DLQ persistence, retry+backoff
- [x] Registered in `data/provider.go` ProviderSet and `cmd/worker/wire.go`
- [ ] `AlertConsumer` for `warehouse.inventory.low_stock_alert` ‚Üí deferred to P2

---

## üü° Open P1 Issues

### NOTIF-P1-001: Worker GitOps Missing Secret Reference for Provider Keys

**File**: `gitops/apps/notification/base/worker-deployment.yaml`

**Problem**: The worker deployment has no `secretRef`. Email API keys (SendGrid/SES), SMS API keys (Twilio), Telegram bot token, and FCM service account credentials must be injected as environment variables from Kubernetes Secrets ‚Äî not plain ConfigMaps.

```yaml
# Missing:
- secretRef:
    name: notification-secrets
```

Currently only `configMapRef: overlays-config` is mounted. If these credentials are baked into the ConfigMap, they are visible to anyone with `kubectl get cm` access ‚Üí credential exposure.

**Resolution** ‚úÖ **FIXED 2026-02-22**:
- [x] Added `secretRef: name: notification-secrets` to `envFrom` in `gitops/apps/notification/base/worker-deployment.yaml`
- [x] ConfigMap retained for non-sensitive config; credentials injected via K8s Secret

---

### NOTIF-P1-002: Worker GitOps Missing `revisionHistoryLimit` + Liveness/Readiness Probes

**File**: `gitops/apps/notification/base/worker-deployment.yaml`

**Problem**:
1. No `revisionHistoryLimit` ‚Üí unlimited old ReplicaSets accumulate in cluster
2. No `livenessProbe` ‚Üí a hung cron scheduler (e.g., stuck DB connection in `processPendingNotifications`) won't trigger pod restart
3. No `readinessProbe` ‚Üí pod may receive Dapr sidecar traffic before the gRPC server is ready
4. `config` volume at line 68-71 is defined but has no `volumeMount` in the container spec ‚Üí dead config volume

Also: `image: registry-api.tanhdev.com/notification:latest` uses `latest` tag ‚Üí not pinned, breaks reproducible deployments.

**Resolution** ‚úÖ **FIXED 2026-02-22**:
- [x] Added `revisionHistoryLimit: 1` to `spec`
- [x] Added `livenessProbe` + `readinessProbe` (gRPC port 5005, initialDelay 30s/10s)
- [x] Added `volumeMounts` for `config` volume

---

### NOTIF-P1-003: Pubsub Name and Topic Hardcoded ‚Äî Not Config-Driven

**File**: `notification/internal/data/eventbus/order_status_consumer.go:83-84`
**File**: `notification/internal/data/eventbus/system_error_consumer.go:72-73`

**Problem**: Both consumers hardcode `topic` and `pubsub` values:
```go
topic := "orders.order.status_changed"
pubsub := "pubsub-redis"
```

If the pubsub component name changes (e.g., from `pubsub-redis` to `pubsub-rabbitmq` in production), all consumers must be manually updated in code. Compare with order/warehouse services which read these values from `config.Data.Eventbus.DefaultPubsub` and the `constants` package.

**Resolution** ‚úÖ **FIXED 2026-02-22**:
- [x] Added topic constants to `notification/internal/constants/constants.go`:
  - `TopicOrderStatusChanged`, `TopicPaymentConfirmed`, `TopicPaymentFailed`, `TopicReturnApproved`, `TopicRefundCompleted`
- [x] Both consumers now read `pubsub` from `config.Data.Eventbus.DefaultPubsub` with `"pubsub-redis"` fallback
- [x] `config.AppConfig` injected via Wire into all consumer constructors

---

### NOTIF-P1-004: `GetPendingNotifications` Has No `FOR UPDATE SKIP LOCKED`

**File**: `notification/cmd/worker/notification_worker.go:113`

**Problem**: `repo.GetPendingNotifications(ctx, batchSize)` likely uses a plain `SELECT ... WHERE status='pending' LIMIT 100`. If worker is scaled to 2+ replicas, two workers may fetch the same notifications ‚Üí send duplicates ‚Üí customer receives 2 "order shipped" emails.

The notification DB row is updated to `"sending"` only **after** the batch is fetched (line 208). There is no atomic compare-and-swap or `FOR UPDATE SKIP LOCKED` guard at the query level.

**Resolution** ‚úÖ **ALREADY FIXED** (pre-existing):
- [x] `GetPendingNotifications` at `notification/internal/repository/notification/notification.go:146` already uses `.Set("gorm:query_option", "FOR UPDATE SKIP LOCKED")`
- [x] `GetFailedNotifications` also uses `FOR UPDATE SKIP LOCKED` (line 175)

---

### NOTIF-P1-005: `SendSystemError` Creates Notification Record But Bypasses Outbox

**File**: `notification/internal/biz/notification/notification.go:290-296`

**Problem**: `SendSystemError` calls `repo.Create(ctx, notification)` **directly** without using `uc.transaction + uc.outboxRepo` path. This means the notification is persisted but the worker is only informed by polling ‚Äî not by an outbox event.

More critically, if the notification record is created but the DB connection drops before the worker polls, the system error alert may be **silently delayed by up to 30 seconds** (next polling window). For critical system errors (P0 incidents), 30s delay in alerting is unacceptable.

**Resolution** ‚úÖ **FIXED 2026-02-22**:
- [x] `SendSystemError` now delegates to `uc.SendNotification()` which uses the outbox transaction path (atomic `repo.Create` + `outboxRepo.Save`)
- [x] The outbox relay worker publishes the `notification.created` event; worker picks it up essentially immediately (no 30s delay)

---

## üìã Event Publishing Necessity Check

### Is `notification.created` (outbox) necessary?

| Justification | Verdict |
|--------------|---------|
| Worker polls DB every 30s ‚Üí acceptable latency for order/promotional notifications | ‚úÖ Polling sufficient |
| But system errors need <5s alerting ‚Üí outbox polling adds latency | ‚ö†Ô∏è See NOTIF-P1-005 |

**The `notification.created` outbox event guarantees durable creation** ‚Üí the worker will pick it up. This is correct for transactional notifications. **Justified**.

### Is `notification.delivered` / `notification.failed` event necessary?

These lifecycle events are published by `NotificationSender` after each send. Currently no service is observed consuming these. If the analytics/loyalty service needs delivery receipts in the future, the event is pre-provisioned. **Justified as infrastructure investment but no current consumer**.

---

## üìã Event Subscription Necessity Check

### Current Subscriptions

| Topic | Handler | Needed? |
|-------|---------|---------|
| `orders.order.status_changed` | `HandleOrderStatusChanged` | ‚úÖ Yes ‚Äî triggers order creation Telegram alert |
| `system.errors` | `HandleSystemError` | ‚úÖ Yes ‚Äî triggers ops Telegram alert |

### Missing Subscriptions (Should Exist)

| Topic | Required Handler | Priority |
|-------|----------------|---------|
| `payment.confirmed` | Email receipt + Push | üî¥ P0 |
| `payment.failed` | Email alert + Push | üî¥ P0 |
| `return.approved` | Email + Push | üü° P1 |
| `refund.completed` | Email + Push | üü° P1 |
| `warehouse.inventory.low_stock_alert` | Push to seller | üîµ P2 |

---

## üìã Worker & Cron Job Checks

### Notification Worker (`cmd/worker/notification_worker.go`)

| Component | Running? | Schedule | Notes |
|-----------|---------|---------|----|
| **ProcessPendingNotifications** | ‚úÖ Yes | Every 30s | Batch size 100; expires check; scheduled-for-later skip |
| **RetryFailedNotifications** | ‚úÖ Yes | Every 5min | Filters by `next_retry_at <= NOW()`; exponential backoff + 20% jitter |
| **QuietHours enforcement** | ‚úÖ Yes | At process time | Per-user timezone; overnight window handled; reschedules to quiet-hours end |
| **Rate limit enforcement** | ‚úÖ Yes | At process time | `CountDailyNotifications` vs `MaxNotificationsPerDay` |
| **Outbox relay worker** | ‚ùì Unknown | ‚Äî | `outbox_publisher.go` exists; is OutboxWorker registered in `cmd/worker/main.go`? |
| **DLQ drain / dead_letter cleanup** | ‚ùå None | ‚Äî | DLQ events accumulate indefinitely; no cron to retry or alert on stuck DLQ events |
| **Processed event cleanup** | ‚ùå None | ‚Äî | `processed_events` table grows unbounded; needs TTL-based cleanup |

---

## üìã Data Consistency Matrix

| Data Pair | Consistency Level | Risk |
|-----------|-----------------|------|
| Notification record ‚Üî outbox event | ‚úÖ Atomic (same TX) | Safe |
| Notification `status` ‚Üî delivery log | ‚úÖ Consistent | Delivery log created before status update |
| Notification status `sending` ‚Üî duplicate send | ‚ö†Ô∏è Risk | No `FOR UPDATE SKIP LOCKED` in GetPendingNotifications (NOTIF-P1-004) |
| `processed_events` ‚Üî notification send | ‚úÖ Idempotent | Check + mark with event ID |
| System error notification ‚Üî outbox | ‚ö†Ô∏è Risk | `SendSystemError` bypasses outbox path (NOTIF-P1-005) |
| User preference ‚Üî channel enablement at send | ‚úÖ Checked | Preference check in `SendNotification` + at worker process time |
| DLQ events ‚Üî ops awareness | ‚ö†Ô∏è Risk | No drain consumer ‚Üí DLQ can grow silently |
| `notification.delivered` event ‚Üî analytics | üîµ Low | Published but currently no consumer |

---

## üìã GitOps Config Checks

### Notification Worker (`gitops/apps/notification/base/worker-deployment.yaml`)

| Check | Status |
|-------|--------|
| `securityContext: runAsNonRoot: true, runAsUser: 65532` | ‚úÖ |
| `dapr.io/enabled: "true"` + `app-id: "notification-worker"` + `app-port: "5005"` | ‚úÖ |
| `initContainers`: consul + redis + postgres | ‚úÖ |
| `resources: requests + limits` | ‚úÖ |
| `secretRef: name: notification-secrets` | ‚ùå **MISSING** (NOTIF-P1-001) |
| `revisionHistoryLimit` | ‚ùå **MISSING** (NOTIF-P1-002) |
| `livenessProbe` + `readinessProbe` | ‚ùå **MISSING** (NOTIF-P1-002) |
| `volumeMounts` for `config` volume | ‚ùå Volume defined but no mount |
| Image tag pinned (not `latest`) | ‚ùå **`image: ...notification:latest`** |

---

## üìã Edge Cases Not Yet Handled

| Edge Case | Risk | Recommendation |
|-----------|------|----------------|
| User has no push device token (never logged in on mobile) | üü° | Push notification creation will fail with `ErrInsufficientRecipientInfo` ‚Üí permanent failure ‚Üí no retry for other channels (email not attempted) | Each notification should be channel-specific; if push fails permanently, try email |
| Quiet hours timezone `""` ‚Üí falls back to UTC | üîµ | User in UTC+7 (Bangkok) with no timezone set gets quiet hours enforced in UTC ‚Üí wrong window | Warn and prompt user to set timezone; default to order-country timezone |
| `notification.ExpiresAt` set to past on creation | üü° | Notification will be created successfully but immediately marked `failed` on first worker poll | Validate `ExpiresAt > now` before creating notification record |
| Concurrent `GlobalUnsubscribe` + `Subscribe` calls | üîµ | Race condition: preference update without transaction ‚Üí lost update | Use `UPDATE ... WHERE version = ?` optimistic locking on preference record |
| Customer changes email between order placement and order shipped notification | üîµ | Notification was created with old email at order time | Resolve email dynamically at send time from Customer service, not at creation time |
| Telegram bot down during system error flood (10+ services erroring) | üü° | All system error notifications queue up with `status='pending'` ‚Üí worker processes all at once ‚Üí Telegram rate limit hit ‚Üí all retried with backoff | Add per-channel rate limiting at the worker send level (not just per-user) |
| `processedEventRepo.IsEventProcessed` DB timeout ‚Üí skips idempotency check ‚Üí processes duplicate | üü° | In `system_error_consumer`: `continue` on error (line 141); in `order_status_consumer`: returns error (line 163) | Standardize: transient DB error on idempotency check should return error (not continue) to trigger Dapr retry |
| `MaxAttempts = 3` but `retryBaseDelay = 5min`: max delivery time = 5+10min = 15min for transient failure | üîµ | For time-sensitive notifications (OTP, payment receipt), 15min total window is too long | Allow per-notification override of `MaxAttempts` and `retryBaseDelay` based on notification type/priority |

---

## üîß Remediation Actions

### üî¥ Fix Now (Missing Critical Business Notifications)

- [ ] **NOTIF-P0-001**: Expand `processOrderStatusChanged` to handle `‚Üí shipped`, `‚Üí delivered`, `‚Üí cancelled`, `‚Üí failed`, `‚Üí refunded` transitions; use formatOrderStatusChangedMessage (currently dead code) for the new transitions
- [ ] **NOTIF-P0-002**: Add `PaymentEventConsumer` for `payment.confirmed` + `payment.failed` and `ReturnEventConsumer` for `return.approved` + `refund.completed`

### üü° Fix Soon (Reliability / Security)

- [ ] **NOTIF-P1-001**: Create `notification-secrets` K8s Secret; add `secretRef` to `worker-deployment.yaml`; remove credentials from ConfigMap
- [ ] **NOTIF-P1-002**: Add `revisionHistoryLimit: 1`, `livenessProbe`, `readinessProbe`; add `volumeMounts`; pin `image` tag
- [ ] **NOTIF-P1-003**: Read `pubsub` from `config.Data.Eventbus.DefaultPubsub`; use `constants.TopicOrderStatusChanged` in order consumer
- [ ] **NOTIF-P1-004**: Add `FOR UPDATE SKIP LOCKED` to `GetPendingNotifications` query
- [ ] **NOTIF-P1-005**: Use outbox or direct send in `SendSystemError` for <5s alerting latency

### üîµ Monitor / Document

- [ ] Verify `OutboxWorker` is registered and running in `cmd/worker/main.go`
- [ ] Add DLQ drain cron: re-process or alert on `dead_letter_events WHERE resolved=false AND created_at < NOW() - INTERVAL '1h'`
- [ ] Add processed_events TTL cleanup: DELETE `WHERE processed_at < NOW() - INTERVAL '7 days'`
- [ ] Standardize idempotency error handling: both consumers should `return error` (not `continue`) on `IsEventProcessed` DB failures
- [ ] Add per-channel send rate limiting to prevent Telegram/SMS provider throttle on alert floods
- [ ] Consider priority queue: `urgent` notifications bypass 30s polling (use outbox event to trigger immediate send)

---

## ‚úÖ What Is Working Well

| Area | Notes |
|------|-------|
| Atomic notification + outbox creation | `repo.Create` + `outboxRepo.Save` in single DB tx |
| Per-user idempotency via correlationID | Prevents duplicate sends on DLQ replay |
| Quiet hours with overnight support | Correctly handles 22:00‚Äì07:00 spans |
| Daily frequency cap per channel | `CountDailyNotifications` enforced before every send |
| Exponential backoff + jitter | 5min base ‚Üí 1h max, 20% jitter prevents thundering herd |
| DLQ persistence on exhaustion | Failed events saved to `dead_letter_events` table |
| Event idempotency via processedEventRepo | 1-minute dedup bucket prevents duplicate Telegram alerts |
| Permanent failure detection | No-retry for: expired, opted-out, missing recipient, bad channel |
| Delivery log on every attempt | Full response details (code, providerMessageID, error) |
| SMTP fallback for email | Falls back to SMTP when primary email provider DOWN |
