# Checklist: Khá»Ÿi táº¡o Kubernetes (K8s) vÃ  k3d

## ğŸ“‹ Má»¥c lá»¥c
1. [Prerequisites & Installation](#prerequisites--installation)
2. [k3d Setup](#k3d-setup)
3. [Kubernetes Basics](#kubernetes-basics)
4. [Common Operations](#common-operations)
5. [Troubleshooting](#troubleshooting)
6. [Best Practices](#best-practices)

---

## ğŸ”§ Prerequisites & Installation

### System Requirements
- [x] Kiá»ƒm tra há»‡ Ä‘iá»u hÃ nh (Windows/Linux/macOS)
  - âœ… **Káº¿t quáº£:** Ubuntu 24.04.3 LTS (Noble Numbat) - Server: 192.168.1.112
- [x] Äáº£m báº£o cÃ³ quyá»n admin/root
  - âœ… **Káº¿t quáº£:** User: `tuananh` (cÃ³ thá»ƒ dÃ¹ng sudo)
- [x] Kiá»ƒm tra dung lÆ°á»£ng á»• cá»©ng (tá»‘i thiá»ƒu 20GB free)
  - âœ… **Káº¿t quáº£:** á»” chÃ­nh: 229.8G (nvme1n1p3) - Äá»§ dung lÆ°á»£ng
- [x] Kiá»ƒm tra RAM (tá»‘i thiá»ƒu 4GB, khuyáº¿n nghá»‹ 8GB+)
  - âœ… **Káº¿t quáº£:** RAM: 31GB total, 30GB available - Ráº¥t tá»‘t

### Resource Planning (K3S Cluster - Single Node)
- [x] **SYSTEM:** 6GB
  - âœ… OS (Ubuntu): 2GB
  - âœ… K3s Components: 2GB
  - âœ… Buffer: 2GB
- [x] **INFRASTRUCTURE:** 12.5GB
  - âœ… PostgreSQL (all DBs): 6GB
  - âœ… Redis: 1.5GB
  - âœ… Elasticsearch: 3GB
  - âœ… RabbitMQ/Dapr: 1.5GB
  - âœ… Consul: 512MB
- [x] **CORE SERVICES (Single Replica):** 9GB
  - âœ… Gateway: 1GB
  - âœ… Auth: 512MB
  - âœ… User: 512MB
  - âœ… Customer: 512MB
  - âœ… Order: 1GB
  - âœ… Payment: 1GB
  - âœ… Catalog: 512MB
  - âœ… Warehouse: 512MB
  - âœ… Shipping: 512MB
  - âœ… Fulfillment: 512MB
  - âœ… Pricing: 512MB
  - âœ… Promotion: 512MB
  - âœ… Loyalty: 512MB
  - âœ… Review: 512MB
  - âœ… Notification: 256MB
  - âœ… Location: 256MB
  - âœ… Search: 512MB
- [x] **MONITORING:** 4.5GB
  - âœ… Prometheus: 2GB (7d retention)
  - âœ… Grafana: 512MB
  - âœ… Loki: 1.5GB (7d retention)
  - âœ… Jaeger: 512MB (memory)
- [x] **Tá»”NG Cá»˜NG:** ~32GB
  - âœ… **ÄÃ¡nh giÃ¡:** Server cÃ³ 31GB RAM, phÃ¹ há»£p vá»›i yÃªu cáº§u (cÃ³ thá»ƒ cáº§n tá»‘i Æ°u hoáº·c thÃªm RAM náº¿u cáº§n buffer)

### Storage Planning (Multi-Tier Storage Strategy)
- [x] **nvme1n1 (232.9GB) - CURRENT OS DISK:**
  - âœ… Keep as-is (Ubuntu already installed)
  - âœ… `/` (root): 50GB
  - âœ… `/var/lib/docker`: 100GB (move here)
  - âœ… `/var/lib/rancher`: 50GB (K3s data)
  - âœ… Free: ~30GB buffer
- [x] **nvme0n1 (238.5GB) - HOT DATABASES:**
  - âœ… Mount as `/data/hot`
  - âœ… PostgreSQL: 100GB
  - âœ… Redis: 10GB
  - âœ… Elasticsearch (hot): 40GB
  - âœ… Prometheus (0-3d): 30GB
  - âœ… Loki (0-3d): 20GB
  - âœ… Free: ~38GB
  - âš¡âš¡âš¡ **Performance:** <1ms latency
- [x] **sdb (223.6GB SSD) - WARM DATA:**
  - âœ… Mount as `/data/warm`
  - âœ… Elasticsearch (warm): 80GB
  - âœ… Prometheus (3-7d): 50GB
  - âœ… Loki (3-7d): 40GB
  - âœ… Application cache: 30GB
  - âœ… Free: ~23GB
  - âš¡âš¡ **Performance:** <5ms latency
- [x] **sda (931.5GB HDD) - COLD STORAGE:**
  - âœ… Mount as `/data/cold`
  - âœ… Prometheus archive (7-30d): 200GB
  - âœ… Loki archive (7-30d): 150GB
  - âœ… Database backups: 150GB
  - âœ… MinIO/Object Storage: 250GB
  - âœ… Application backups: 50GB
  - âœ… Docker registry cache: 50GB
  - âœ… Free: ~81GB
  - âš¡ **Performance:** ~10ms latency
- [ ] **Storage Setup Tasks:**

#### Step 1: Kiá»ƒm tra vÃ  xÃ¡c nháº­n cÃ¡c á»• Ä‘Ä©a
- [x] Kiá»ƒm tra cÃ¡c á»• Ä‘Ä©a: `lsblk -a`
  - âœ… **Káº¿t quáº£:** 
    - nvme0n1 (238.5G) - ChÆ°a format (HOT)
    - sdb (223.6G) - ChÆ°a format (WARM)
    - sda (931.5G) - ChÆ°a format (COLD)
    - nvme1n1 (232.9G) - ÄÃ£ sá»­ dá»¥ng cho OS
- [x] Kiá»ƒm tra filesystem hiá»‡n táº¡i: `df -m`
  - âœ… **Káº¿t quáº£:** Chá»‰ cÃ³ nvme1n1 Ä‘Æ°á»£c mount (OS)

#### Step 2: Format cÃ¡c á»• Ä‘Ä©a
- [x] **Format nvme0n1 (HOT - NVMe):**
  - âœ… **Káº¿t quáº£:** ÄÃ£ format thÃ nh cÃ´ng vá»›i ext4
- [x] **Format sdb (WARM - SSD):**
  - âœ… **Káº¿t quáº£:** ÄÃ£ format thÃ nh cÃ´ng vá»›i ext4
- [x] **Format sda (COLD - HDD):**
  - âœ… **Káº¿t quáº£:** ÄÃ£ format thÃ nh cÃ´ng vá»›i ext4

#### Step 3: Táº¡o mount points vÃ  mount
- [x] **Táº¡o mount points:**
  - âœ… **Káº¿t quáº£:** ÄÃ£ táº¡o thÃ nh cÃ´ng
- [x] **Mount cÃ¡c á»• Ä‘Ä©a:**
  - âœ… **Káº¿t quáº£:** ÄÃ£ mount thÃ nh cÃ´ng
- [x] **Kiá»ƒm tra mount:**
  - âœ… **Káº¿t quáº£:**
    - `/dev/nvme0n1` â†’ `/data/hot` (234G, ext4, 1% used)
    - `/dev/sdb` â†’ `/data/warm` (220G, ext4, 1% used)
    - `/dev/sda` â†’ `/data/cold` (916G, ext4, 1% used)

#### Step 4: Cáº¥u hÃ¬nh /etc/fstab cho auto-mount
- [x] **Láº¥y UUID cá»§a cÃ¡c á»• Ä‘Ä©a:**
  - âœ… **Káº¿t quáº£:**
    - nvme0n1: `5caf348e-2f96-45d8-a9e1-51550669029c`
    - sdb: `d413e9cf-1d7b-427f-9915-d7e34a1a2bd9`
    - sda: `2be93147-eaf2-480b-a9a1-5d27e7f322f0`
- [x] **Backup /etc/fstab:**
  - âœ… **Káº¿t quáº£:** ÄÃ£ backup (hoáº·c Ä‘Ã£ cáº¥u hÃ¬nh)
- [x] **ThÃªm entries vÃ o /etc/fstab:**
  - âœ… **Káº¿t quáº£:** ÄÃ£ thÃªm thÃ nh cÃ´ng cÃ¡c entries:
    - UUID=5caf348e-2f96-45d8-a9e1-51550669029c â†’ /data/hot
    - UUID=d413e9cf-1d7b-427f-9915-d7e34a1a2bd9 â†’ /data/warm
    - UUID=2be93147-eaf2-480b-a9a1-5d27e7f322f0 â†’ /data/cold
  
  **Giáº£i thÃ­ch cÃ¡c tham sá»‘:**
  - `defaults`: Sá»­ dá»¥ng cÃ¡c mount options máº·c Ä‘á»‹nh (rw, suid, dev, exec, auto, nouser, async)
  - `noatime`: KhÃ´ng update access time (tÄƒng performance)
  - `0`: KhÃ´ng dump filesystem
  - `2`: Filesystem sáº½ Ä‘Æ°á»£c kiá»ƒm tra báº±ng fsck á»Ÿ láº§n boot thá»© 2 (sau root filesystem)
- [x] **Test fstab configuration:**
  - âœ… **Káº¿t quáº£:** Test thÃ nh cÃ´ng, khÃ´ng cÃ³ lá»—i
    - `/dev/nvme0n1` â†’ `/data/hot` (234G, 1% used)
    - `/dev/sdb` â†’ `/data/warm` (220G, 1% used)
    - `/dev/sda` â†’ `/data/cold` (916G, 1% used)
  - âœ… **Káº¿t luáº­n:** CÃ¡c á»• Ä‘Ä©a sáº½ tá»± Ä‘á»™ng mount khi reboot

#### Step 5: Táº¡o cáº¥u trÃºc thÆ° má»¥c cho services
- [x] **Táº¡o thÆ° má»¥c cho HOT storage (/data/hot):**
  - âœ… **Káº¿t quáº£:** ÄÃ£ táº¡o thÃ nh cÃ´ng
    - postgresql, redis, elasticsearch-hot, prometheus-hot, loki-hot
  - [x] **Kiá»ƒm tra UID/GID hiá»‡n cÃ³:**
    - âœ… **Káº¿t quáº£:** 
      - UID 999: dnsmasq (Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng)
      - UID 1000: tuananh (Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng)
  - [ ] **Giáº£i phÃ¡p Ownership:**
    
    **Option 1: Äá»ƒ root vÃ  Ä‘á»ƒ Kubernetes tá»± quáº£n lÃ½ (Recommended)**
    - Khi deploy trong Kubernetes, containers sáº½ cháº¡y vá»›i SecurityContext riÃªng
    - Kubernetes sáº½ tá»± Ä‘á»™ng set ownership khi mount volumes
    - Giá»¯ ownership hiá»‡n táº¡i (root) hoáº·c:
      ```bash
      sudo chown -R root:root /data/hot/*
      ```
    
    **Option 2: Táº¡o cÃ¡c user/group riÃªng (Náº¿u cáº§n)**
    ```bash
    # Táº¡o postgres user/group (UID 1001)
    sudo groupadd -g 1001 postgres
    sudo useradd -u 1001 -g 1001 -r -s /bin/false postgres
    
    # Táº¡o redis user/group (UID 1002)
    sudo groupadd -g 1002 redis
    sudo useradd -u 1002 -g 1002 -r -s /bin/false redis
    
    # Táº¡o elasticsearch user/group (UID 1003)
    sudo groupadd -g 1003 elasticsearch
    sudo useradd -u 1003 -g 1003 -r -s /bin/false elasticsearch
    
    # Set ownership
    sudo chown -R 1001:1001 /data/hot/postgresql
    sudo chown -R 1002:1002 /data/hot/redis
    sudo chown -R 1003:1003 /data/hot/elasticsearch-hot
    ```
    
    **Khuyáº¿n nghá»‹:** Sá»­ dá»¥ng Option 1 (Ä‘á»ƒ Kubernetes quáº£n lÃ½) vÃ¬:
    - ÄÆ¡n giáº£n hÆ¡n
    - Kubernetes sáº½ tá»± Ä‘á»™ng handle ownership khi mount volumes
    - CÃ³ thá»ƒ cáº¥u hÃ¬nh trong Pod SecurityContext khi deploy
- [x] **Táº¡o thÆ° má»¥c cho WARM storage (/data/warm):**
  - âœ… **Káº¿t quáº£:** ÄÃ£ táº¡o thÃ nh cÃ´ng
    - elasticsearch-warm, prometheus-warm, loki-warm, app-cache
- [x] **Táº¡o thÆ° má»¥c cho COLD storage (/data/cold):**
  - âœ… **Káº¿t quáº£:** ÄÃ£ táº¡o thÃ nh cÃ´ng
    - prometheus-archive, loki-archive, db-backups, minio, app-backups, docker-registry
- [x] **Kiá»ƒm tra cáº¥u trÃºc thÆ° má»¥c:**
  - âœ… **Káº¿t quáº£:** Táº¥t cáº£ thÆ° má»¥c Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng
    - HOT: postgresql, redis, elasticsearch-hot, prometheus-hot, loki-hot
    - WARM: elasticsearch-warm, prometheus-warm, loki-warm, app-cache
    - COLD: prometheus-archive, loki-archive, db-backups, minio, app-backups, docker-registry
  - [ ] **Sá»­a ownership (Optional - Ä‘á»ƒ Kubernetes quáº£n lÃ½):**
    ```bash
    # Náº¿u muá»‘n Ä‘á»“ng nháº¥t ownership vá» root (khuyáº¿n nghá»‹)
    sudo chown -R root:root /data/warm/elasticsearch-warm
    ```

#### Step 6: Cáº¥u hÃ¬nh Docker data directory
- [x] **Kiá»ƒm tra Docker data directory hiá»‡n táº¡i:**
  - âœ… **Káº¿t quáº£:** Docker Root Dir: `/var/lib/docker` (thÆ° má»¥c máº·c Ä‘á»‹nh)
- [ ] **Kiá»ƒm tra dung lÆ°á»£ng Docker Ä‘ang sá»­ dá»¥ng:**
  ```bash
  sudo du -sh /var/lib/docker
  ```
- [x] **Táº¡o thÆ° má»¥c má»›i cho Docker:**
  - âœ… **Káº¿t quáº£:** `/var/lib/docker` Ä‘Ã£ tá»“n táº¡i (thÆ° má»¥c máº·c Ä‘á»‹nh)
- [ ] **ÄÃ¡nh giÃ¡:**
  - Docker Ä‘ang á»Ÿ `/var/lib/docker` trÃªn root filesystem (nvme1n1)
  - Root filesystem cÃ³ 229.8G vá»›i 83.8G available (12% used)
  - **Quyáº¿t Ä‘á»‹nh:** CÃ³ thá»ƒ giá»¯ nguyÃªn hoáº·c di chuyá»ƒn sang `/data/hot/docker` náº¿u cáº§n
  - **Khuyáº¿n nghá»‹:** Giá»¯ nguyÃªn vÃ¬ root partition cÃ²n nhiá»u dung lÆ°á»£ng
- [ ] **Di chuyá»ƒn Docker data (Optional - chá»‰ khi cáº§n):**
  ```bash
  # Chá»‰ thá»±c hiá»‡n náº¿u muá»‘n di chuyá»ƒn sang /data/hot/docker
  # Stop Docker
  sudo systemctl stop docker
  
  # Di chuyá»ƒn data
  sudo mv /var/lib/docker /data/hot/docker
  sudo ln -s /data/hot/docker /var/lib/docker
  
  # Start Docker
  sudo systemctl start docker
  ```

#### Step 7: Cáº¥u hÃ¬nh K3s data directory
- [ ] **Táº¡o thÆ° má»¥c cho K3s:**
  ```bash
  sudo mkdir -p /var/lib/rancher
  ```
- [ ] **K3s sáº½ tá»± Ä‘á»™ng sá»­ dá»¥ng /var/lib/rancher khi cÃ i Ä‘áº·t**

#### Step 8: Test I/O performance
- [ ] **Test write performance cho HOT (nvme0n1):**
  ```bash
  sudo dd if=/dev/zero of=/data/hot/testfile bs=1G count=1 oflag=direct
  sudo rm /data/hot/testfile
  ```
- [ ] **Test write performance cho WARM (sdb):**
  ```bash
  sudo dd if=/dev/zero of=/data/warm/testfile bs=1G count=1 oflag=direct
  sudo rm /data/warm/testfile
  ```
- [ ] **Test write performance cho COLD (sda):**
  ```bash
  sudo dd if=/dev/zero of=/data/cold/testfile bs=1G count=1 oflag=direct
  sudo rm /data/cold/testfile
  ```

#### Step 9: Setup StorageClass trong K3s (sau khi cluster Ä‘Æ°á»£c táº¡o)
- [ ] **Táº¡o Local Path Provisioner cho Hot Storage**
- [ ] **Táº¡o Local Path Provisioner cho Warm Storage**
- [ ] **Táº¡o Local Path Provisioner cho Cold Storage**

### Docker Installation
- [x] CÃ i Ä‘áº·t Docker Desktop (Windows/macOS) hoáº·c Docker Engine (Linux)
  - âœ… **Káº¿t quáº£:** Docker Engine Ä‘Ã£ cÃ i Ä‘áº·t
- [x] Kiá»ƒm tra Docker Ä‘Ã£ cháº¡y: `docker --version`
  - âœ… **Káº¿t quáº£:** Docker Client Version: 28.2.2
- [x] Kiá»ƒm tra Docker daemon: `docker ps`
  - âœ… **Káº¿t quáº£:** Docker daemon Ä‘ang cháº¡y, khÃ´ng cÃ³ container nÃ o (sáºµn sÃ ng)
- [ ] Äáº£m báº£o Docker cÃ³ quyá»n truy cáº­p

### kubectl Installation
- [x] CÃ i Ä‘áº·t kubectl CLI tool
  - âœ… **Káº¿t quáº£:** ÄÃ£ cÃ i Ä‘áº·t thÃ nh cÃ´ng qua snap
- [x] Kiá»ƒm tra version: `kubectl version --client`
  - âœ… **Káº¿t quáº£:** Client Version: v1.34.2, Kustomize Version: v5.7.1
- [x] Cáº¥u hÃ¬nh PATH environment variable (náº¿u cáº§n)
  - âœ… **Káº¿t quáº£:** PATH Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh tá»± Ä‘á»™ng (snap)
- [ ] Kiá»ƒm tra kubectl cÃ³ hoáº¡t Ä‘á»™ng: `kubectl cluster-info` (sáº½ test sau khi cÃ³ cluster)

### k3d Installation
- [x] CÃ i Ä‘áº·t k3d (via script/package manager)
  - âœ… **Káº¿t quáº£:** ÄÃ£ cÃ i Ä‘áº·t thÃ nh cÃ´ng
- [x] Kiá»ƒm tra version: `k3d version`
  - âœ… **Káº¿t quáº£:** k3d version v5.8.3, k3s version v1.31.5-k3s1 (default)
- [ ] XÃ¡c nháº­n k3d cÃ³ thá»ƒ táº¡o cluster (sáº½ test á»Ÿ bÆ°á»›c tiáº¿p theo)

---

## ğŸ¯ K3S Cluster Configuration Suggestions (Based on 19 Services)

### Namespace Structure
- [ ] **infrastructure** - Databases, Redis, Consul, Elasticsearch, Dapr
- [ ] **core-services** - Core business services (Customer, Order, Payment, Catalog, etc.)
- [ ] **support-services** - Support services (Auth, Notification, Search, Location)
- [ ] **integration-services** - Gateway, Admin Panel, Frontend
- [ ] **monitoring** - Prometheus, Grafana, Loki, Jaeger
- [ ] **default** - System pods

### Service Ports Mapping (19 Services)
- [ ] **Gateway Service**: 8080 (NodePort/LoadBalancer)
- [ ] **Auth Service**: 8002 (ClusterIP)
- [ ] **User Service**: 8001 (ClusterIP)
- [ ] **Customer Service**: 8003 (ClusterIP)
- [ ] **Order Service**: 8004 (ClusterIP)
- [ ] **Payment Service**: 8005 (ClusterIP)
- [ ] **Catalog Service**: 8001 (ClusterIP) - Note: Same port as User, use different namespace
- [ ] **Warehouse Service**: 8008 (ClusterIP)
- [ ] **Shipping Service**: 8007 (ClusterIP)
- [ ] **Fulfillment Service**: 8009 (ClusterIP)
- [ ] **Pricing Service**: 8010 (ClusterIP)
- [ ] **Promotion Service**: 8011 (ClusterIP)
- [ ] **Loyalty Service**: 8012 (ClusterIP)
- [ ] **Review Service**: 8013 (ClusterIP)
- [ ] **Notification Service**: Internal (ClusterIP)
- [ ] **Search Service**: Internal (ClusterIP)
- [ ] **Location Service**: Internal (ClusterIP)
- [ ] **Admin Panel**: 3001 (NodePort)
- [ ] **Frontend Service**: 3000 (NodePort)

### Infrastructure Services (Deploy First)
- [ ] **PostgreSQL** (all databases)
  - Storage: `/data/hot` (nvme0n1) - 100GB
  - Memory: 6GB
  - Namespace: `infrastructure`
- [ ] **Redis**
  - Storage: `/data/hot` (nvme0n1) - 10GB
  - Memory: 1.5GB
  - Namespace: `infrastructure`
- [ ] **Elasticsearch**
  - Hot data: `/data/hot` (nvme0n1) - 40GB
  - Warm data: `/data/warm` (sdb) - 80GB
  - Memory: 3GB
  - Namespace: `infrastructure`
- [ ] **Consul** (Service Discovery)
  - Memory: 512MB
  - Namespace: `infrastructure`
- [ ] **Dapr** (Service Mesh)
  - Memory: 1.5GB
  - Namespace: `infrastructure`

### Core Services Resource Allocation
- [ ] **Gateway Service** (1GB RAM)
  - Requests: CPU 200m, Memory 512Mi
  - Limits: CPU 1000m, Memory 1Gi
  - Namespace: `integration-services`
- [ ] **Auth Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `support-services`
- [ ] **User Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Customer Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Order Service** (1GB RAM)
  - Requests: CPU 200m, Memory 512Mi
  - Limits: CPU 1000m, Memory 1Gi
  - Namespace: `core-services`
- [ ] **Payment Service** (1GB RAM)
  - Requests: CPU 200m, Memory 512Mi
  - Limits: CPU 1000m, Memory 1Gi
  - Namespace: `core-services`
- [ ] **Catalog Service** (512MB RAM)
  - Requests: CPU 200m, Memory 256Mi
  - Limits: CPU 1000m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Warehouse Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Shipping Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Fulfillment Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Pricing Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Promotion Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Loyalty Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`
- [ ] **Review Service** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `core-services`

### Support Services Resource Allocation
- [ ] **Notification Service** (256MB RAM)
  - Requests: CPU 50m, Memory 128Mi
  - Limits: CPU 250m, Memory 256Mi
  - Namespace: `support-services`
- [ ] **Search Service** (512MB RAM)
  - Requests: CPU 200m, Memory 256Mi
  - Limits: CPU 1000m, Memory 512Mi
  - Namespace: `support-services`
- [ ] **Location Service** (256MB RAM)
  - Requests: CPU 50m, Memory 128Mi
  - Limits: CPU 250m, Memory 256Mi
  - Namespace: `support-services`

### Frontend Services Resource Allocation
- [ ] **Admin Panel** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `integration-services`
- [ ] **Frontend Service** (512MB RAM)
  - Requests: CPU 200m, Memory 256Mi
  - Limits: CPU 1000m, Memory 512Mi
  - Namespace: `integration-services`

### Monitoring Services Resource Allocation
- [ ] **Prometheus** (2GB RAM)
  - Hot data (0-3d): `/data/hot` - 30GB
  - Warm data (3-7d): `/data/warm` - 50GB
  - Archive (7-30d): `/data/cold` - 200GB
  - Namespace: `monitoring`
- [ ] **Grafana** (512MB RAM)
  - Requests: CPU 100m, Memory 256Mi
  - Limits: CPU 500m, Memory 512Mi
  - Namespace: `monitoring`
- [ ] **Loki** (1.5GB RAM)
  - Hot data (0-3d): `/data/hot` - 20GB
  - Warm data (3-7d): `/data/warm` - 40GB
  - Archive (7-30d): `/data/cold` - 150GB
  - Namespace: `monitoring`
- [ ] **Jaeger** (512MB RAM)
  - Memory-only storage
  - Namespace: `monitoring`

### StorageClass Configuration
- [ ] **hot-storage** (nvme0n1)
  - Type: Local Path Provisioner
  - Path: `/data/hot`
  - Performance: <1ms latency
  - Use for: PostgreSQL, Redis, Elasticsearch hot, Prometheus/Loki 0-3d
- [ ] **warm-storage** (sdb SSD)
  - Type: Local Path Provisioner
  - Path: `/data/warm`
  - Performance: <5ms latency
  - Use for: Elasticsearch warm, Prometheus/Loki 3-7d, Application cache
- [ ] **cold-storage** (sda HDD)
  - Type: Local Path Provisioner
  - Path: `/data/cold`
  - Performance: ~10ms latency
  - Use for: Archives, backups, MinIO, Docker registry cache

### Deployment Strategy

**Option 1: Manual Deployment (Scripts)**
- [ ] Deploy using scripts in `k8s-local/`
- [ ] See: [STAGING_DEPLOYMENT_REVIEW.md](./STAGING_DEPLOYMENT_REVIEW.md)

**Option 2: GitOps vá»›i ArgoCD** â­ **RECOMMENDED**
- [ ] Install ArgoCD
- [ ] Setup Git repository cho K8s manifests
- [ ] Create ArgoCD Applications
- [ ] Deploy via GitOps workflow
- [ ] See: [ARGOCD_SETUP_GUIDE.md](./ARGOCD_SETUP_GUIDE.md) vÃ  [STAGING_DEPLOYMENT_ARGOCD_PLAN.md](./STAGING_DEPLOYMENT_ARGOCD_PLAN.md)

### Deployment Order (Dependencies)
1. [x] **Infrastructure Layer** (Deploy first) âœ… **COMPLETED**
   - âœ… PostgreSQL â†’ âœ… Redis â†’ âœ… Consul â†’ âœ… Elasticsearch â†’ âœ… Dapr
   - **Status:** Táº¥t cáº£ services Ä‘ang Running vÃ  Ready
   - **Pods:**
     - PostgreSQL: Running (37m uptime)
     - Redis: Running (37m uptime)
     - Consul: Running (6m uptime)
     - Elasticsearch: Running (5m uptime)
     - Dapr: All components Running (dapr-operator, dapr-sidecar-injector, dapr-sentry, dapr-placement-server, dapr-dashboard)
2. [ ] **Support Services** (Deploy second)
   - Auth Service â†’ Notification Service â†’ Search Service â†’ Location Service
3. [ ] **Core Services** (Deploy third)
   - Customer Service â†’ User Service â†’ Catalog Service â†’ Pricing Service
   - Warehouse Service â†’ Order Service â†’ Payment Service
   - Shipping Service â†’ Fulfillment Service â†’ Promotion Service â†’ Loyalty Service â†’ Review Service
4. [ ] **Integration Services** (Deploy last)
   - Gateway Service â†’ Admin Panel â†’ Frontend Service
5. [ ] **Monitoring** (Can deploy anytime)
   - Prometheus â†’ Grafana â†’ Loki â†’ Jaeger

### Infrastructure Deployment Script
- [x] **Script Ä‘Ã£ Ä‘Æ°á»£c táº¡o:** `deploy-infrastructure.sh`
  - âœ… Script tá»± Ä‘á»™ng deploy: PostgreSQL, Redis, Consul, Elasticsearch, Dapr
  - âœ… Sá»­ dá»¥ng StorageClasses Ä‘Ã£ táº¡o (hot-storage, warm-storage, cold-storage)
  - âœ… Deploy vÃ o namespace `infrastructure`
  - âœ… Tá»± Ä‘á»™ng wait cho deployments/statefulsets ready
  - âœ… Hiá»ƒn thá»‹ status vÃ  access points sau khi deploy

- [x] **Script Ä‘Ã£ Ä‘Æ°á»£c cháº¡y thÃ nh cÃ´ng:**
  - âœ… Táº¥t cáº£ infrastructure services Ä‘Ã£ Ä‘Æ°á»£c deploy
  - âœ… Storage requests Ä‘Ã£ Ä‘Æ°á»£c giáº£m xuá»‘ng 50% (PostgreSQL: 50Gi, Redis: 5Gi, ES hot: 20Gi, ES warm: 40Gi)
  - âœ… Image Consul Ä‘Ã£ Ä‘Æ°á»£c sá»­a thÃ nh `hashicorp/consul:1.17`
  - âœ… Readiness probes Ä‘Ã£ Ä‘Æ°á»£c thÃªm cho Consul

- [x] **Kiá»ƒm tra sau khi deploy:**
  - âœ… **Káº¿t quáº£:** Táº¥t cáº£ services Ä‘ang Running vÃ  Ready
    - PostgreSQL: Running (37m uptime) âœ…
    - Redis: Running (37m uptime) âœ…
    - Consul: Running (6m uptime) âœ…
    - Elasticsearch: Running (5m uptime) âœ…
    - Dapr: All components Running âœ…
  
- [x] **Access Points sau khi deploy:**
  - âœ… PostgreSQL: `postgresql.infrastructure.svc.cluster.local:5432`
  - âœ… Redis: `redis.infrastructure.svc.cluster.local:6379`
  - âœ… Consul UI: `http://<node-ip>:30500` (NodePort)
  - âœ… Elasticsearch: `http://elasticsearch.infrastructure.svc.cluster.local:9200`
  - âœ… Dapr Dashboard: Available in dapr-system namespace

### Ingress Configuration (Domain: tanhdev.com)
**LÆ°u Ã½:** Sá»­ dá»¥ng Nginx Manager trÃªn server khÃ¡c thay vÃ¬ Ingress Controller trong cluster

- [ ] **Cáº¥u hÃ¬nh Nginx Manager bÃªn ngoÃ i:**
  - **Gateway Service** (Port 8080)
    - Domain: `api.tanhdev.com` hoáº·c `gateway.tanhdev.com`
    - Proxy pass: `http://192.168.1.112:8080`
    - TLS: SSL/TLS certificates táº¡i Nginx Manager
  - **Frontend Service** (Port 3000)
    - Domain: `www.tanhdev.com` hoáº·c `tanhdev.com`
    - Proxy pass: `http://192.168.1.112:3000`
    - TLS: SSL/TLS certificates táº¡i Nginx Manager
  - **Admin Panel** (Port 3001)
    - Domain: `admin.tanhdev.com`
    - Proxy pass: `http://192.168.1.112:3001`
    - TLS: SSL/TLS certificates táº¡i Nginx Manager
    - Authentication: Require admin access (Basic Auth hoáº·c OAuth2)
  - **Monitoring** (Optional - Internal access recommended)
    - Grafana: `grafana.tanhdev.com` â†’ `http://192.168.1.112:3000` (náº¿u expose)
    - Prometheus: `prometheus.tanhdev.com` â†’ `http://192.168.1.112:9090` (náº¿u expose)
    - Consul UI: `consul.tanhdev.com` â†’ `http://192.168.1.112:8500` (náº¿u expose)
    - Authentication: Strong authentication required (VPN/Basic Auth)

### DNS Configuration (tanhdev.com)
- [ ] **A Records** (Point to Nginx Manager server IP - khÃ´ng pháº£i K3S server)
  - `api.tanhdev.com` â†’ [Nginx Manager Server IP]
  - `gateway.tanhdev.com` â†’ [Nginx Manager Server IP] (optional, alias of api)
  - `www.tanhdev.com` â†’ [Nginx Manager Server IP]
  - `tanhdev.com` â†’ [Nginx Manager Server IP]
  - `admin.tanhdev.com` â†’ [Nginx Manager Server IP]
- [ ] **CNAME Records** (Optional - for monitoring)
  - `grafana.tanhdev.com` â†’ [Nginx Manager Server IP]
  - `prometheus.tanhdev.com` â†’ [Nginx Manager Server IP]
  - `consul.tanhdev.com` â†’ [Nginx Manager Server IP]
- [ ] **SSL/TLS Certificates**
  - [ ] Setup SSL/TLS certificates táº¡i Nginx Manager (Let's Encrypt hoáº·c custom)
  - [ ] Configure auto-renewal cho certificates
  - [ ] Test certificate renewal

### Service Discovery & Networking
- [ ] **Consul** for service discovery
- [ ] **Dapr** for service mesh (pub/sub, state management)
- [ ] **Internal DNS** for service-to-service communication
- [ ] **Network Policies** for security isolation

### Recommended k3d Cluster Configuration

**Option 1: Single Agent (Development/Testing) - Khuyáº¿n nghá»‹ Ä‘á»ƒ báº¯t Ä‘áº§u**
```bash
k3d cluster create ecommerce-cluster \
  --port "8080:8080@loadbalancer" \
  --port "3000:3000@loadbalancer" \
  --port "3001:3001@loadbalancer" \
  --port "8500:8500@loadbalancer" \
  --port "9090:9090@loadbalancer" \
  --agents 1 \
  --k3s-arg "--disable=traefik@server:0" \
  --volume /data/hot:/data/hot \
  --volume /data/warm:/data/warm \
  --volume /data/cold:/data/cold
```

**Option 2: Multiple Agents (Production-like) - Khi cáº§n HA vÃ  performance**
```bash
k3d cluster create ecommerce-cluster \
  --port "8080:8080@loadbalancer" \
  --port "3000:3000@loadbalancer" \
  --port "3001:3001@loadbalancer" \
  --port "8500:8500@loadbalancer" \
  --port "9090:9090@loadbalancer" \
  --agents 2 \
  --k3s-arg "--disable=traefik@server:0" \
  --volume /data/hot:/data/hot \
  --volume /data/warm:/data/warm \
  --volume /data/cold:/data/cold
```

**LÆ°u Ã½ vá» k3s-arg:**
- Khi cÃ³ nhiá»u node (control plane + agents), cáº§n chá»‰ Ä‘á»‹nh node filter
- `@server:0` = Ã¡p dá»¥ng cho server node (control plane)
- `@all` = Ã¡p dá»¥ng cho táº¥t cáº£ nodes
- `@agents:*` = Ã¡p dá»¥ng cho táº¥t cáº£ agent nodes

**So sÃ¡nh sá»‘ lÆ°á»£ng Agents:**

| Agents | Use Case | Pros | Cons |
|--------|----------|------|------|
| **1 agent** | Development, Testing, Single server | âœ… ÄÆ¡n giáº£n, Ã­t resource, dá»… quáº£n lÃ½ | âŒ KhÃ´ng cÃ³ HA, single point of failure |
| **2 agents** | Production (small-medium) | âœ… HA cÆ¡ báº£n, load distribution | âš ï¸ Cáº§n nhiá»u resource hÆ¡n |
| **3+ agents** | Production (large scale) | âœ… High availability, tá»‘t cho production | âš ï¸ Phá»©c táº¡p, tá»‘n nhiá»u resource |

**Khuyáº¿n nghá»‹ cho setup hiá»‡n táº¡i:**
- **Báº¯t Ä‘áº§u vá»›i 1 agent** Ä‘á»ƒ test vÃ  validate
- Server cÃ³ 31GB RAM, Ä‘á»§ cho 1 agent vá»›i 19 services (~32GB requirement)
- **Sau Ä‘Ã³ scale lÃªn 2-3 agents** khi:
  - Cáº§n high availability
  - Traffic tÄƒng cao
  - CÃ³ thÃªm server resources

**Note:** 
- Disable Traefik (k3d default) vÃ¬ báº¡n Ä‘Ã£ cÃ³ Gateway Service
- **KhÃ´ng cáº§n Ingress Controller** vÃ¬ Ä‘Ã£ cÃ³ Nginx Manager trÃªn server khÃ¡c
- Mount storage volumes Ä‘á»ƒ sá»­ dá»¥ng multi-tier storage
- Expose ports Ä‘á»ƒ Nginx Manager bÃªn ngoÃ i cÃ³ thá»ƒ proxy Ä‘áº¿n:
  - `8080`: Gateway Service â†’ Nginx Manager sáº½ route `api.tanhdev.com` Ä‘áº¿n Ä‘Ã¢y
  - `3000`: Frontend Service â†’ Nginx Manager sáº½ route `www.tanhdev.com` Ä‘áº¿n Ä‘Ã¢y
  - `3001`: Admin Panel â†’ Nginx Manager sáº½ route `admin.tanhdev.com` Ä‘áº¿n Ä‘Ã¢y
  - `8500`: Consul UI (optional - cÃ³ thá»ƒ chá»‰ internal access)
  - `9090`: Prometheus (optional - cÃ³ thá»ƒ chá»‰ internal access)

**Kiáº¿n trÃºc vá»›i Nginx Manager bÃªn ngoÃ i:**
```
Internet (Port 80/443)
    â†“
[Nginx Manager - Server khÃ¡c]
    â†“ (Proxy Ä‘áº¿n K3S cluster)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  K3S Cluster (192.168.1.112)       â”‚
â”‚  â”œâ”€ api.tanhdev.com â†’ :8080        â”‚
â”‚  â”œâ”€ www.tanhdev.com â†’ :3000        â”‚
â”‚  â””â”€ admin.tanhdev.com â†’ :3001      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cáº¥u hÃ¬nh Nginx Manager cáº§n thiáº¿t:**
- SSL/TLS termination táº¡i Nginx Manager
- Proxy pass Ä‘áº¿n cÃ¡c ports tÆ°Æ¡ng á»©ng trÃªn server K3S
- Load balancing (náº¿u cÃ³ nhiá»u nodes)

**So sÃ¡nh 2 cÃ¡ch tiáº¿p cáº­n:**

| Aspect | Local Setup (Nginx Manager bÃªn ngoÃ i) | AWS Setup (Ingress Controller) |
|--------|--------------------------------------|--------------------------------|
| **Entry Point** | Nginx Manager (server khÃ¡c) | Ingress Controller (trong cluster) |
| **Expose Ports** | 8080, 3000, 3001 (services) | 80, 443 (Ingress Controller) |
| **Service Types** | LoadBalancer/NodePort | ClusterIP (khÃ´ng expose) |
| **SSL/TLS** | Táº¡i Nginx Manager | Táº¡i Ingress Controller |
| **Routing** | Nginx Manager proxy pass | Ingress Controller route |
| **Security** | Services expose ra ngoÃ i | Services chá»‰ accessible qua Ingress |

**Káº¿t luáº­n:**
- **Local:** Cáº§n expose 8080, 3000, 3001 vÃ¬ Nginx Manager bÃªn ngoÃ i cáº§n proxy Ä‘áº¿n
- **AWS:** Chá»‰ expose 80/443, services lÃ  ClusterIP, Ingress Controller route traffic vÃ o

### Ingress Controller Setup
- [x] **KhÃ´ng cáº§n cÃ i Ä‘áº·t Ingress Controller trong cluster**
  - âœ… **LÃ½ do:** ÄÃ£ cÃ³ Nginx Manager trÃªn server khÃ¡c Ä‘á»©ng trÆ°á»›c
  - âœ… **Kiáº¿n trÃºc:** Nginx Manager â†’ Proxy â†’ K3S Cluster (ports 8080, 3000, 3001)
  - âœ… **Lá»£i Ã­ch:** 
    - SSL/TLS termination táº¡i Nginx Manager (táº­p trung)
    - KhÃ´ng cáº§n expose ports 80/443 trong cluster
    - Quáº£n lÃ½ routing táº­p trung táº¡i má»™t nÆ¡i
    - Giáº£m complexity trong cluster

**Náº¿u muá»‘n cÃ i Ingress Controller trong cluster (khÃ´ng khuyáº¿n nghá»‹ cho local setup):**
- [ ] **Install Nginx Ingress Controller**
  ```bash
  kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
  ```
- [ ] **Verify Installation**
  ```bash
  kubectl get pods -n ingress-nginx
  kubectl get svc -n ingress-nginx
  ```

### ğŸ“ AWS Deployment - Ingress Controller (80/443)
**LÆ°u Ã½:** Khi deploy lÃªn AWS, sáº½ sá»­ dá»¥ng Ingress Controller vá»›i ports 80/443

- [ ] **AWS EKS/K3S trÃªn EC2 vá»›i Ingress Controller:**
  - [ ] **Install Nginx Ingress Controller trÃªn AWS:**
    ```bash
    kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/aws/deploy.yaml
    ```
  - [ ] **Expose ports 80/443 trong cluster:**
    - Port 80: HTTP traffic
    - Port 443: HTTPS traffic (SSL/TLS)
  - [ ] **Cáº¥u hÃ¬nh LoadBalancer Service:**
    - Type: LoadBalancer (AWS sáº½ táº¡o ALB/NLB tá»± Ä‘á»™ng)
    - Ports: 80, 443
    - SSL/TLS: Sá»­ dá»¥ng AWS Certificate Manager (ACM) hoáº·c Cert-Manager vá»›i Let's Encrypt
  - [ ] **Ingress Resources cho AWS:**
    - `api.tanhdev.com` â†’ Gateway Service (ClusterIP, port 8080 - khÃ´ng expose ra ngoÃ i)
    - `www.tanhdev.com` â†’ Frontend Service (ClusterIP, port 3000 - khÃ´ng expose ra ngoÃ i)
    - `admin.tanhdev.com` â†’ Admin Panel (ClusterIP, port 3001 - khÃ´ng expose ra ngoÃ i)
  - [ ] **Service Types cho AWS:**
    - Gateway, Frontend, Admin Panel: **ClusterIP** (chá»‰ accessible trong cluster)
    - Ingress Controller: **LoadBalancer** (expose ports 80/443)
    - **LÆ°u Ã½:** KhÃ´ng cáº§n expose ports 8080, 3000, 3001 vÃ¬ Ingress sáº½ route tá»« 80/443 vÃ o
  - [ ] **DNS Configuration cho AWS:**
    - Point A records Ä‘áº¿n AWS Load Balancer DNS/IP
    - Sá»­ dá»¥ng Route53 hoáº·c DNS provider khÃ¡c
  - [ ] **SSL/TLS Certificates trÃªn AWS:**
    - Option 1: AWS Certificate Manager (ACM) - tÃ­ch há»£p vá»›i ALB
    - Option 2: Cert-Manager vá»›i Let's Encrypt
    - Auto-renewal certificates

- [ ] **AWS k3d Cluster Configuration (khi deploy lÃªn AWS):**
  ```bash
  # Khi deploy lÃªn AWS EC2 vá»›i Ingress Controller
  # CHá»ˆ expose ports 80/443 cho Ingress Controller
  # KHÃ”NG expose ports 8080, 3000, 3001 (services sáº½ lÃ  ClusterIP)
  k3d cluster create ecommerce-cluster-aws \
    --port "80:80@loadbalancer" \
    --port "443:443@loadbalancer" \
    --agents 1 \
    --k3s-arg "--disable=traefik" \
    --volume /data/hot:/data/hot \
    --volume /data/warm:/data/warm \
    --volume /data/cold:/data/cold
  ```
  
  **Giáº£i thÃ­ch:**
  - Ports 80/443: Cho Ingress Controller (entry point duy nháº¥t)
  - Ports 8080, 3000, 3001: **KHÃ”NG cáº§n expose** - services lÃ  ClusterIP, chá»‰ accessible qua Ingress
  - Ingress Controller sáº½ route traffic tá»« 80/443 vÃ o cÃ¡c services bÃªn trong cluster
  
  **Hoáº·c vá»›i EKS:**
  - Sá»­ dá»¥ng AWS Load Balancer Controller
  - Ingress vá»›i ALB (Application Load Balancer)
  - SSL/TLS termination táº¡i ALB
  - Services lÃ  ClusterIP, khÃ´ng expose trá»±c tiáº¿p

- [ ] **AWS Architecture vá»›i Ingress:**
  ```
  Internet (Port 80/443)
      â†“
  [AWS Load Balancer (ALB/NLB)]
      â†“
  [Ingress Controller (Nginx)]
      â†“ (Route dá»±a trÃªn domain)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  K3S/EKS Cluster                    â”‚
  â”‚  â”œâ”€ api.tanhdev.com â†’ Gateway:8080 â”‚
  â”‚  â”œâ”€ www.tanhdev.com â†’ Frontend:3000â”‚
  â”‚  â””â”€ admin.tanhdev.com â†’ Admin:3001 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ```

- [ ] **AWS Security Groups:**
  - Allow inbound: Ports 80, 443 tá»« Internet (cho Ingress Controller)
  - **KHÃ”NG cáº§n** allow inbound ports 8080, 3000, 3001 (services lÃ  ClusterIP, chá»‰ accessible trong cluster)
  - Allow outbound: All traffic

- [ ] **AWS Storage:**
  - EBS volumes cho `/data/hot`, `/data/warm`, `/data/cold`
  - Hoáº·c EFS (Elastic File System) cho shared storage
  - Backup strategy vá»›i AWS Backup hoáº·c S3

---

## ğŸš€ k3d Setup

### Cluster Creation
- [x] Táº¡o cluster Ä‘áº§u tiÃªn: `k3d cluster create <name>`
  - âœ… **Káº¿t quáº£:** Cluster `ecommerce-cluster` Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng!
  - âœ… **Cáº¥u hÃ¬nh:**
    - 1 server node (control plane): `k3d-ecommerce-cluster-server-0`
    - 1 agent node: `k3d-ecommerce-cluster-agent-0`
    - LoadBalancer: `k3d-ecommerce-cluster-serverlb`
    - Ports exposed: 8080, 3000, 3001, 8500, 9090
    - Volumes mounted: /data/hot, /data/warm, /data/cold
    - Traefik disabled: âœ…
- [ ] Táº¡o cluster vá»›i custom port: `k3d cluster create --port "8080:80@loadbalancer"`
- [ ] Táº¡o cluster vá»›i nhiá»u nodes: `k3d cluster create --agents 3`
- [ ] Táº¡o cluster vá»›i custom config: `k3d cluster create --config <config-file>`

### Cluster Management
- [x] Liá»‡t kÃª cÃ¡c cluster: `k3d cluster list`
  - âœ… **Káº¿t quáº£:** `ecommerce-cluster` - 1/1 servers, 1/1 agents, LoadBalancer: true
- [x] Kiá»ƒm tra cluster status: `k3d cluster get ecommerce-cluster`
  - âœ… **Káº¿t quáº£:** Cluster Ä‘ang cháº¡y tá»‘t
- [x] Kiá»ƒm tra nodes: `kubectl get nodes`
  - âœ… **Káº¿t quáº£:** 
    - `k3d-ecommerce-cluster-server-0`: Ready (control-plane, master) - v1.31.5+k3s1
    - `k3d-ecommerce-cluster-agent-0`: Ready - v1.31.5+k3s1
- [x] Kiá»ƒm tra cluster info: `kubectl cluster-info`
  - âœ… **Káº¿t quáº£:** Kubernetes control plane Ä‘ang cháº¡y táº¡i https://0.0.0.0:38039
  - âœ… CoreDNS vÃ  Metrics-server Ä‘ang cháº¡y
- [x] Kiá»ƒm tra kubeconfig: `kubectl config view` vÃ  `kubectl config current-context`
  - âœ… **Káº¿t quáº£:** Context hiá»‡n táº¡i: `k3d-ecommerce-cluster`
- [x] Kiá»ƒm tra system pods: `kubectl get pods -A`
  - âœ… **Káº¿t quáº£:** Táº¥t cáº£ system pods Ä‘ang Running:
    - coredns: Running
    - local-path-provisioner: Running
    - metrics-server: Running
- [ ] Start cluster: `k3d cluster start <name>`
- [ ] Stop cluster: `k3d cluster stop <name>`
- [ ] Delete cluster: `k3d cluster delete <name>`
- [ ] Delete táº¥t cáº£ clusters: `k3d cluster delete --all`

### Scale Agents (ThÃªm/XÃ³a Nodes)
- [ ] **ThÃªm agent node vÃ o cluster hiá»‡n cÃ³ (Scale Up):**
  ```bash
  # ThÃªm 1 agent node vÃ o cluster ecommerce-cluster
  k3d node create agent-2 --cluster ecommerce-cluster
  
  # Hoáº·c thÃªm nhiá»u agents cÃ¹ng lÃºc
  k3d node create agent-2 agent-3 --cluster ecommerce-cluster
  ```
  
  **LÆ°u Ã½:** 
  - âœ… **KHÃ”NG cáº§n setup láº¡i tá»« Ä‘áº§u** - chá»‰ cáº§n thÃªm node má»›i
  - âœ… CÃ¡c services Ä‘Ã£ deploy sáº½ tá»± Ä‘á»™ng distribute trÃªn nodes má»›i
  - âœ… KhÃ´ng máº¥t data, khÃ´ng cáº§n migrate
  - âœ… CÃ³ thá»ƒ thÃªm nodes báº¥t cá»© lÃºc nÃ o
  
- [ ] **Kiá»ƒm tra nodes sau khi scale:**
  ```bash
  kubectl get nodes
  kubectl get nodes -o wide
  ```
  
- [ ] **XÃ³a agent node (Scale Down):**
  ```bash
  # XÃ³a node cá»¥ thá»ƒ
  k3d node delete agent-2
  
  # Hoáº·c xÃ³a nhiá»u nodes
  k3d node delete agent-2 agent-3
  ```
  
  **LÆ°u Ã½:**
  - Kubernetes sáº½ tá»± Ä‘á»™ng drain pods tá»« node trÆ°á»›c khi xÃ³a
  - Pods sáº½ Ä‘Æ°á»£c reschedule sang nodes cÃ²n láº¡i
  - Äáº£m báº£o cÃ³ Ä‘á»§ resources trÃªn nodes cÃ²n láº¡i

**VÃ­ dá»¥: Scale tá»« 1 â†’ 2 agents:**
```bash
# 1. Kiá»ƒm tra cluster hiá»‡n táº¡i
k3d cluster list
kubectl get nodes

# 2. ThÃªm agent node má»›i
k3d node create agent-2 --cluster ecommerce-cluster

# 3. Kiá»ƒm tra nodes má»›i
kubectl get nodes
# Sáº½ tháº¥y: k3d-ecommerce-cluster-server-0 (control plane)
#          k3d-ecommerce-cluster-agent-0 (agent 1)
#          k3d-ecommerce-cluster-agent-1 (agent 2 - má»›i thÃªm)

# 4. Kiá»ƒm tra pods distribution
kubectl get pods -A -o wide
# Pods sáº½ tá»± Ä‘á»™ng distribute trÃªn cÃ¡c nodes
```

### kubeconfig Setup
- [x] Kiá»ƒm tra kubeconfig: `kubectl config view`
  - âœ… **Káº¿t quáº£:** kubeconfig Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘Ãºng
- [x] Kiá»ƒm tra context hiá»‡n táº¡i: `kubectl config current-context`
  - âœ… **Káº¿t quáº£:** `k3d-ecommerce-cluster` (Ä‘Ã£ Ä‘Æ°á»£c set lÃ m context máº·c Ä‘á»‹nh)
- [ ] Merge kubeconfig: `k3d kubeconfig merge <name> --kubeconfig-switch-context` (náº¿u cáº§n)
- [ ] Switch context: `kubectl config use-context <context-name>` (náº¿u cÃ³ nhiá»u clusters)

### Volume Mount Verification
- [x] **Kiá»ƒm tra volumes Ä‘Ã£ mount vÃ o cluster nodes:**
  - âœ… **Káº¿t quáº£:** Volumes Ä‘Ã£ Ä‘Æ°á»£c mount vÃ o cluster nodes qua `--volume` flag
  - âš ï¸ **LÆ°u Ã½:** Volumes khÃ´ng tá»± Ä‘á»™ng mount vÃ o pods - cáº§n mount qua PersistentVolumes hoáº·c hostPath

- [x] **Kiá»ƒm tra volumes trong pod (cáº§n mount volumes vÃ o pod):**
  - âœ… **Káº¿t quáº£:** Volumes Ä‘Ã£ Ä‘Æ°á»£c mount thÃ nh cÃ´ng vÃ o pod!
  - âœ… **HOT storage (/data/hot):**
    - postgresql, redis, elasticsearch-hot, prometheus-hot, loki-hot
  - âœ… **WARM storage (/data/warm):**
    - elasticsearch-warm, prometheus-warm, loki-warm, app-cache
  - âœ… **COLD storage (/data/cold):**
    - prometheus-archive, loki-archive, db-backups, minio, app-backups, docker-registry
  
  **Giáº£i thÃ­ch:**
  - Volumes Ä‘Æ°á»£c mount vÃ o cluster nodes qua `--volume` flag khi táº¡o cluster
  - Äá»ƒ pods sá»­ dá»¥ng, cáº§n mount volumes vÃ o pod spec (hostPath hoáº·c PersistentVolume)
  - Khi deploy services, sáº½ mount volumes trong deployment/pod spec

- [ ] **Táº¡o PersistentVolumes cho storage tiers (sáº½ lÃ m khi deploy services):**
  - Táº¡o PV cho hot-storage, warm-storage, cold-storage
  - Táº¡o PVC khi deploy services
  - Services sáº½ tá»± Ä‘á»™ng mount volumes khi deploy

### Registry Setup (Optional)
- [ ] Táº¡o local registry: `k3d registry create <name>`
- [ ] Káº¿t ná»‘i registry vá»›i cluster: `k3d cluster create --registry-use <registry-name>`
- [ ] Kiá»ƒm tra registry: `docker ps | grep registry`

---

## â˜¸ï¸ Kubernetes Basics

### Cluster Information
- [ ] Kiá»ƒm tra cluster info: `kubectl cluster-info`
- [ ] Kiá»ƒm tra nodes: `kubectl get nodes`
- [ ] Kiá»ƒm tra node details: `kubectl describe node <node-name>`
- [ ] Kiá»ƒm tra API resources: `kubectl api-resources`

### Namespaces
- [x] Liá»‡t kÃª namespaces: `kubectl get namespaces` hoáº·c `kubectl get ns`
  - âœ… **Káº¿t quáº£:** Táº¥t cáº£ namespaces Ä‘ang Active:
    - `infrastructure` - Cho databases, Redis, Consul, Elasticsearch, Dapr âœ…
    - `core-services` - Cho 12 core business services âœ…
    - `support-services` - Cho Auth, Notification, Search, Location âœ…
    - `integration-services` - Cho Gateway, Admin Panel, Frontend âœ…
    - `monitoring` - Cho Prometheus, Grafana, Loki, Jaeger âœ…
    - System namespaces: default, kube-system, kube-public, kube-node-lease âœ…
- [x] Táº¡o namespace: `kubectl create namespace <name>`
  - âœ… **Káº¿t quáº£:** ÄÃ£ táº¡o thÃ nh cÃ´ng 5 namespaces cho cÃ¡c nhÃ³m services
- [ ] XÃ³a namespace: `kubectl delete namespace <name>`
- [ ] Set default namespace: `kubectl config set-context --current --namespace=<name>`

### StorageClasses Setup (Multi-Tier Storage)
- [x] **Kiá»ƒm tra StorageClasses hiá»‡n cÃ³:**
  - âœ… **Káº¿t quáº£:** CÃ³ StorageClass máº·c Ä‘á»‹nh `local-path` vá»›i provisioner `rancher.io/local-path`
  
- [x] **Táº¡o StorageClass cho HOT storage (nvme0n1):**
  - âœ… **Káº¿t quáº£:** StorageClass `hot-storage` Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng
  - âœ… **Cáº¥u hÃ¬nh:** basePath=/data/hot, provisioner=rancher.io/local-path
- [x] **Táº¡o StorageClass cho WARM storage (sdb SSD):**
  - âœ… **Káº¿t quáº£:** StorageClass `warm-storage` Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng
  - âœ… **Cáº¥u hÃ¬nh:** basePath=/data/warm, provisioner=rancher.io/local-path
- [x] **Táº¡o StorageClass cho COLD storage (sda HDD):**
  - âœ… **Káº¿t quáº£:** StorageClass `cold-storage` Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng
  - âœ… **Cáº¥u hÃ¬nh:** basePath=/data/cold, provisioner=rancher.io/local-path
- [x] **Kiá»ƒm tra StorageClasses Ä‘Ã£ táº¡o:**
  - âœ… **Káº¿t quáº£:** Táº¥t cáº£ 4 StorageClasses Ä‘ang hoáº¡t Ä‘á»™ng:
    - `hot-storage` - basePath=/data/hot âœ…
    - `warm-storage` - basePath=/data/warm âœ…
    - `cold-storage` - basePath=/data/cold âœ…
    - `local-path` (default) - basePath máº·c Ä‘á»‹nh âœ…
  
**LÆ°u Ã½:**
- Sá»­ dá»¥ng `rancher.io/local-path` provisioner (cÃ³ sáºµn trong k3d)
- `volumeBindingMode: WaitForFirstConsumer` - Ä‘á»£i pod Ä‘Æ°á»£c táº¡o má»›i bind volume
- Má»—i StorageClass trá» Ä‘áº¿n path tÆ°Æ¡ng á»©ng trÃªn host

**Náº¿u StorageClass vá»›i basePath khÃ´ng hoáº¡t Ä‘á»™ng (local-path-provisioner khÃ´ng há»— trá»£):**

**Giáº£i phÃ¡p thay tháº¿: Sá»­ dá»¥ng PersistentVolumes vá»›i hostPath**

- [ ] **Táº¡o PersistentVolumes cho HOT storage:**
  ```bash
  cat <<EOF | kubectl apply -f -
  apiVersion: v1
  kind: PersistentVolume
  metadata:
    name: hot-storage-pv
  spec:
    capacity:
      storage: 200Gi
    accessModes:
      - ReadWriteOnce
    persistentVolumeReclaimPolicy: Retain
    storageClassName: hot-storage
    hostPath:
      path: /data/hot
  EOF
  ```

- [ ] **Táº¡o PersistentVolumes cho WARM storage:**
  ```bash
  cat <<EOF | kubectl apply -f -
  apiVersion: v1
  kind: PersistentVolume
  metadata:
    name: warm-storage-pv
  spec:
    capacity:
      storage: 200Gi
    accessModes:
      - ReadWriteOnce
    persistentVolumeReclaimPolicy: Retain
    storageClassName: warm-storage
    hostPath:
      path: /data/warm
  EOF
  ```

- [ ] **Táº¡o PersistentVolumes cho COLD storage:**
  ```bash
  cat <<EOF | kubectl apply -f -
  apiVersion: v1
  kind: PersistentVolume
  metadata:
    name: cold-storage-pv
  spec:
    capacity:
      storage: 800Gi
    accessModes:
      - ReadWriteOnce
    persistentVolumeReclaimPolicy: Retain
    storageClassName: cold-storage
    hostPath:
      path: /data/cold
  EOF
  ```

**Hoáº·c sá»­ dá»¥ng hostPath volumes trá»±c tiáº¿p trong Deployment/Pod specs** (Ä‘Æ¡n giáº£n nháº¥t):
- KhÃ´ng cáº§n StorageClass hoáº·c PV
- Mount trá»±c tiáº¿p hostPath trong pod spec
- PhÃ¹ há»£p cho single-node cluster

### Pods
- [ ] Hiá»ƒu khÃ¡i niá»‡m Pod
- [ ] Táº¡o pod tá»« YAML: `kubectl apply -f <pod.yaml>`
- [ ] Liá»‡t kÃª pods: `kubectl get pods` hoáº·c `kubectl get pods -A`
- [ ] Xem pod details: `kubectl describe pod <pod-name>`
- [ ] Xem pod logs: `kubectl logs <pod-name>`
- [ ] XÃ³a pod: `kubectl delete pod <pod-name>`

### Deployments
- [ ] Hiá»ƒu khÃ¡i niá»‡m Deployment
- [ ] Táº¡o deployment: `kubectl create deployment <name> --image=<image>`
- [ ] Táº¡o deployment tá»« YAML: `kubectl apply -f <deployment.yaml>`
- [ ] Liá»‡t kÃª deployments: `kubectl get deployments`
- [ ] Scale deployment: `kubectl scale deployment <name> --replicas=<number>`
- [ ] Xem deployment status: `kubectl rollout status deployment/<name>`
- [ ] Rollback deployment: `kubectl rollout undo deployment/<name>`

### Services
- [ ] Hiá»ƒu cÃ¡c loáº¡i Service (ClusterIP, NodePort, LoadBalancer)
- [ ] Táº¡o service: `kubectl create service <type> <name> --tcp=<port>`
- [ ] Táº¡o service tá»« YAML: `kubectl apply -f <service.yaml>`
- [ ] Liá»‡t kÃª services: `kubectl get services` hoáº·c `kubectl get svc`
- [ ] Port forward: `kubectl port-forward service/<name> <local-port>:<service-port>`
- [ ] Expose deployment: `kubectl expose deployment <name> --type=<type> --port=<port>`

### ConfigMaps & Secrets
- [ ] Hiá»ƒu khÃ¡i niá»‡m ConfigMap
- [ ] Táº¡o ConfigMap: `kubectl create configmap <name> --from-literal=<key>=<value>`
- [ ] Táº¡o ConfigMap tá»« file: `kubectl create configmap <name> --from-file=<file>`
- [ ] Liá»‡t kÃª ConfigMaps: `kubectl get configmaps`
- [ ] Hiá»ƒu khÃ¡i niá»‡m Secret
- [ ] Táº¡o Secret: `kubectl create secret generic <name> --from-literal=<key>=<value>`
- [ ] Liá»‡t kÃª Secrets: `kubectl get secrets`

### Ingress
- [ ] Hiá»ƒu khÃ¡i niá»‡m Ingress
- [ ] CÃ i Ä‘áº·t Ingress Controller (nginx/traefik)
- [ ] Táº¡o Ingress resource: `kubectl apply -f <ingress.yaml>`
- [ ] Liá»‡t kÃª Ingress: `kubectl get ingress`

---

## ğŸ”„ Common Operations

### YAML Files
- [ ] Hiá»ƒu cáº¥u trÃºc YAML cÆ¡ báº£n
- [ ] Táº¡o pod YAML: `kubectl run <name> --image=<image> --dry-run=client -o yaml`
- [ ] Táº¡o deployment YAML: `kubectl create deployment <name> --image=<image> --dry-run=client -o yaml`
- [ ] Validate YAML: `kubectl apply --dry-run=client -f <file.yaml>`
- [ ] Format YAML: `kubectl get <resource> <name> -o yaml`

### Debugging
- [ ] Xem logs: `kubectl logs <pod-name>`
- [ ] Xem logs vá»›i follow: `kubectl logs -f <pod-name>`
- [ ] Xem logs tá»« container cá»¥ thá»ƒ: `kubectl logs <pod-name> -c <container-name>`
- [ ] Exec vÃ o pod: `kubectl exec -it <pod-name> -- /bin/sh`
- [ ] Describe resource: `kubectl describe <resource> <name>`
- [ ] Xem events: `kubectl get events --sort-by=.metadata.creationTimestamp`

### Resource Management
- [ ] Xem resource usage: `kubectl top nodes`
- [ ] Xem pod resource usage: `kubectl top pods`
- [ ] Xem táº¥t cáº£ resources: `kubectl get all`
- [ ] Xem resources trong namespace: `kubectl get all -n <namespace>`
- [ ] XÃ³a táº¥t cáº£ resources: `kubectl delete all --all`

### Labels & Selectors
- [ ] Hiá»ƒu khÃ¡i niá»‡m Labels vÃ  Selectors
- [ ] ThÃªm label: `kubectl label pod <name> <key>=<value>`
- [ ] TÃ¬m pods theo label: `kubectl get pods -l <key>=<value>`
- [ ] XÃ³a label: `kubectl label pod <name> <key>-`

---

## ğŸ› Troubleshooting

### Cluster Issues
- [ ] Kiá»ƒm tra cluster connectivity: `kubectl cluster-info`
- [ ] Kiá»ƒm tra nodes status: `kubectl get nodes`
- [ ] Kiá»ƒm tra node conditions: `kubectl describe node <node-name>`
- [ ] Restart k3d cluster: `k3d cluster stop <name> && k3d cluster start <name>`

### Pod Issues
- [ ] Kiá»ƒm tra pod status: `kubectl get pods`
- [ ] Xem pod events: `kubectl describe pod <pod-name>`
- [ ] Kiá»ƒm tra pod logs: `kubectl logs <pod-name>`
- [ ] Kiá»ƒm tra pod previous logs: `kubectl logs <pod-name> --previous`
- [ ] Kiá»ƒm tra image pull errors
- [ ] Kiá»ƒm tra resource limits

### Network Issues
- [ ] Kiá»ƒm tra service endpoints: `kubectl get endpoints`
- [ ] Kiá»ƒm tra service selector: `kubectl get svc <name> -o yaml`
- [ ] Test connectivity tá»« pod: `kubectl exec <pod-name> -- curl <service-url>`
- [ ] Kiá»ƒm tra DNS: `kubectl exec <pod-name> -- nslookup <service-name>`

### Storage Issues
- [ ] Kiá»ƒm tra PersistentVolumes: `kubectl get pv`
- [ ] Kiá»ƒm tra PersistentVolumeClaims: `kubectl get pvc`
- [ ] Kiá»ƒm tra StorageClass: `kubectl get storageclass`

### Common Commands
- [ ] Xem táº¥t cáº£ resources: `kubectl get all -A`
- [ ] Xem resource vá»›i wide output: `kubectl get pods -o wide`
- [ ] Xem resource YAML: `kubectl get <resource> <name> -o yaml`
- [ ] Xem resource JSON: `kubectl get <resource> <name> -o json`

---

## âœ… Best Practices

### Security
- [ ] KhÃ´ng hardcode credentials trong YAML
- [ ] Sá»­ dá»¥ng Secrets cho sensitive data
- [ ] Sá»­ dá»¥ng RBAC Ä‘á»ƒ quáº£n lÃ½ permissions
- [ ] Regular update images vÃ  dependencies
- [ ] Scan images cho vulnerabilities

### Resource Management
- [ ] Set resource requests vÃ  limits cho pods
- [ ] Sá»­ dá»¥ng namespaces Ä‘á»ƒ organize resources
- [ ] Clean up unused resources Ä‘á»‹nh ká»³
- [ ] Monitor resource usage

### Configuration
- [ ] Sá»­ dá»¥ng ConfigMaps cho configuration
- [ ] Sá»­ dá»¥ng environment variables há»£p lÃ½
- [ ] Version control cho YAML files
- [ ] Sá»­ dá»¥ng Helm charts cho complex applications

### Development Workflow
- [ ] Sá»­ dá»¥ng local k3d cluster cho development
- [ ] Test trÃªn local trÆ°á»›c khi deploy production
- [ ] Sá»­ dá»¥ng GitOps workflow
- [ ] Document changes vÃ  configurations

### Monitoring & Logging
- [ ] Setup monitoring tools (Prometheus/Grafana)
- [ ] Centralized logging (ELK/Loki)
- [ ] Setup alerts cho critical issues
- [ ] Regular review logs vÃ  metrics

---

## ğŸ“š Learning Resources

### Documentation
- [ ] Äá»c Kubernetes official documentation
- [ ] Äá»c k3d documentation
- [ ] Hiá»ƒu Kubernetes architecture
- [ ] Há»c vá» Kubernetes objects vÃ  resources

### Practice
- [ ] Deploy sample applications
- [ ] Practice vá»›i cÃ¡c scenarios khÃ¡c nhau
- [ ] Experiment vá»›i cÃ¡c features
- [ ] Join Kubernetes community

### Tools to Learn
- [ ] kubectl commands vÃ  options
- [ ] k3d commands vÃ  options
- [ ] YAML syntax vÃ  structure
- [ ] Container images vÃ  Docker

---

## ğŸ¯ Quick Reference Commands

```bash
# k3d
k3d cluster create mycluster
k3d cluster list
k3d cluster delete mycluster
k3d kubeconfig merge mycluster

# kubectl basics
kubectl get pods
kubectl get nodes
kubectl get services
kubectl get deployments

# Apply & Delete
kubectl apply -f file.yaml
kubectl delete -f file.yaml
kubectl delete pod <name>

# Debugging
kubectl logs <pod-name>
kubectl describe pod <pod-name>
kubectl exec -it <pod-name> -- /bin/sh

# Port forwarding
kubectl port-forward service/<name> 8080:80
kubectl port-forward pod/<name> 8080:80
```

---

## ğŸ”„ GitOps Setup (ArgoCD) â­ RECOMMENDED

### ArgoCD Installation
- [ ] Install ArgoCD vÃ o cluster
- [ ] Access ArgoCD UI
- [ ] Configure Git repository
- [ ] Setup repository credentials (náº¿u private)
- [ ] See: [ARGOCD_SETUP_GUIDE.md](./ARGOCD_SETUP_GUIDE.md)

### Git Repository Structure
- [ ] Create Git repository cho K8s manifests (hoáº·c folder trong repo hiá»‡n táº¡i)
- [ ] Organize manifests theo structure (infrastructure/, services/, applications/)
- [ ] Setup Kustomize cho multi-environment (staging/production)
- [ ] Copy existing manifests vÃ o repo structure

### ArgoCD Applications
- [ ] Create Infrastructure Application
- [ ] Create Support Services Application
- [ ] Create Core Services Application
- [ ] Create Integration Services Application
- [ ] Configure sync policies (automated cho staging, manual cho production)

### Deployment Workflow
- [ ] Initial deployment via ArgoCD
- [ ] Test sync tá»« Git
- [ ] Test rollback
- [ ] Setup CI/CD integration (optional)
- [ ] See: [STAGING_DEPLOYMENT_ARGOCD_PLAN.md](./STAGING_DEPLOYMENT_ARGOCD_PLAN.md)

---

## ğŸ”„ CI/CD Setup (GitLab)

### GitLab CI/CD Configuration
- [ ] **Táº¡o file `.gitlab-ci.yml`**
  - âœ… **Káº¿t quáº£:** File Ä‘Ã£ Ä‘Æ°á»£c táº¡o vá»›i cÃ¡c stages: build, test, build-docker, deploy
- [ ] **Cáº¥u hÃ¬nh GitLab Variables:**
  - [ ] `CI_REGISTRY_USER` - GitLab registry username
  - [ ] `CI_REGISTRY_PASSWORD` - GitLab registry password
  - [ ] `CI_REGISTRY` - GitLab registry URL (registry.gitlab.com)
  - [ ] `K8S_SERVER_IP` - Server IP (192.168.1.112)
  - [ ] `K8S_USER` - SSH user (tuananh)
  - [ ] `K8S_SSH_PRIVATE_KEY` - SSH private key Ä‘á»ƒ connect Ä‘áº¿n server
  - [ ] `KUBERNETES_NAMESPACE` - Default namespace

### Pipeline Stages
- [ ] **Build Stage:**
  - [ ] Build Go services (19 microservices)
  - [ ] Build artifacts
  - [ ] Store artifacts
- [ ] **Test Stage:**
  - [ ] Run unit tests cho Go services
  - [ ] Run integration tests (náº¿u cÃ³)
  - [ ] Code coverage reports
- [ ] **Build Docker Stage:**
  - [ ] Build Docker images cho táº¥t cáº£ services
  - [ ] Tag images vá»›i commit SHA vÃ  latest
  - [ ] Push images lÃªn GitLab Container Registry
  - [ ] Build Frontend (Next.js)
  - [ ] Build Admin Panel (React)
- [ ] **Deploy Stage:**
  - [ ] Deploy to Staging (develop branch)
  - [ ] Deploy to Production (main branch) - manual approval
  - [ ] Rollout status check
  - [ ] Health checks sau khi deploy

### GitLab Setup Tasks
- [ ] **Setup GitLab Repository:**
  - [ ] Push code lÃªn GitLab
  - [ ] Configure repository settings
  - [ ] Setup branch protection rules
- [ ] **Setup GitLab Container Registry:**
  - [ ] Enable Container Registry trong GitLab project
  - [ ] Verify registry access
  - [ ] Test push/pull images
- [ ] **Setup SSH Keys:**
  - [ ] Generate SSH key pair cho CI/CD
  - [ ] Add public key vÃ o server (authorized_keys)
  - [ ] Add private key vÃ o GitLab CI/CD Variables (K8S_SSH_PRIVATE_KEY)
  - [ ] Test SSH connection tá»« GitLab runner
- [ ] **Setup Kubernetes Access:**
  - [ ] Copy kubeconfig tá»« server
  - [ ] Hoáº·c setup kubectl access qua SSH
  - [ ] Test kubectl commands tá»« GitLab runner
- [ ] **Create Kubernetes Manifests:**
  - [ ] Táº¡o thÆ° má»¥c `k8s/` trong repository
  - [ ] Táº¡o deployment manifests cho tá»«ng service
  - [ ] Táº¡o service manifests
  - [ ] Táº¡o configmaps vÃ  secrets
  - [ ] Táº¡o ingress resources (náº¿u cáº§n)

### Kubernetes Manifests Structure
```
k8s/
â”œâ”€â”€ infrastructure/          # Infrastructure services (PostgreSQL, Redis, etc.)
â”‚   â”œâ”€â”€ postgresql.yaml
â”‚   â”œâ”€â”€ redis.yaml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ services/               # Microservices
â”‚   â”œâ”€â”€ auth-service/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â””â”€â”€ configmap.yaml
â”‚   â”œâ”€â”€ user-service/
â”‚   â”œâ”€â”€ customer-service/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/               # Frontend deployment
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â””â”€â”€ service.yaml
â””â”€â”€ admin-panel/            # Admin panel deployment
    â”œâ”€â”€ deployment.yaml
    â””â”€â”€ service.yaml
```

### CI/CD Best Practices
- [ ] **Branch Strategy:**
  - [ ] `main` branch â†’ Production deployment (manual approval)
  - [ ] `develop` branch â†’ Staging deployment
  - [ ] Feature branches â†’ Build and test only
- [ ] **Image Tagging:**
  - [ ] Use commit SHA for versioning
  - [ ] Tag latest for easy rollback
  - [ ] Semantic versioning cho releases
- [ ] **Deployment Strategy:**
  - [ ] Rolling updates
  - [ ] Health checks before marking ready
  - [ ] Rollback capability
  - [ ] Blue-green deployment (optional)
- [ ] **Security:**
  - [ ] Scan Docker images for vulnerabilities
  - [ ] Use secrets management (GitLab CI/CD Variables)
  - [ ] Limit SSH key permissions
  - [ ] Use service accounts vá»›i minimal permissions

### GitLab Runner Setup (Náº¿u cáº§n self-hosted)
- [ ] **Install GitLab Runner:**
  - [ ] TrÃªn server hoáº·c dedicated machine
  - [ ] Register runner vá»›i GitLab
  - [ ] Configure runner tags
- [ ] **Runner Configuration:**
  - [ ] Docker executor
  - [ ] Resource limits
  - [ ] Cache configuration

### Monitoring CI/CD
- [ ] **Pipeline Monitoring:**
  - [ ] Track pipeline success/failure rates
  - [ ] Monitor deployment times
  - [ ] Alert on failures
- [ ] **Deployment Monitoring:**
  - [ ] Monitor pod status sau khi deploy
  - [ ] Check service health endpoints
  - [ ] Monitor logs cho errors

---

**LÆ°u Ã½:** Checklist nÃ y lÃ  guide tá»•ng quÃ¡t. TÃ¹y vÃ o use case cá»¥ thá»ƒ, báº¡n cÃ³ thá»ƒ cáº§n bá»• sung thÃªm cÃ¡c items phÃ¹ há»£p.

**NgÃ y táº¡o:** $(date)
**Version:** 1.0


